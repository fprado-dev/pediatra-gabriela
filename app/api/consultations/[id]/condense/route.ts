import { createClient } from "@/lib/supabase/server";
import { openai } from "@/lib/openai/client";
import { NextRequest, NextResponse } from "next/server";

export const dynamic = 'force-dynamic';
export const maxDuration = 60;

type CondenseMode = 'summary' | 'bullets' | 'key_info';

interface CondenseRequest {
  field: string;
  mode: CondenseMode;
  originalText: string;
}

const PROMPTS: Record<CondenseMode, (text: string) => string> = {
  summary: (text: string) => `Voc√™ √© um assistente m√©dico especializado em resumir documenta√ß√£o cl√≠nica.

TAREFA: Resuma o seguinte texto da consulta pedi√°trica mantendo:
- Todas as informa√ß√µes m√©dicas relevantes
- Sintomas principais e dura√ß√£o
- Achados significativos do exame
- Medica√ß√µes e doses
- Orienta√ß√µes importantes

REMOVER:
- Detalhes redundantes
- Conversas paralelas
- Contextualiza√ß√µes excessivas

Meta: 30-40% do tamanho original mantendo clareza m√©dica.

TEXTO ORIGINAL:
${text}

Retorne apenas o texto resumido, sem coment√°rios adicionais.`,

  bullets: (text: string) => `Voc√™ √© um assistente m√©dico especializado em organizar documenta√ß√£o cl√≠nica.

TAREFA: Converta o seguinte texto em lista de t√≥picos organizados e concisos.

ESTRUTURA:
‚Ä¢ Sintomas Principais
  - [lista concisa]
‚Ä¢ Exame F√≠sico
  - [achados principais]
‚Ä¢ Conduta
  - [a√ß√µes e orienta√ß√µes]
‚Ä¢ Observa√ß√µes
  - [informa√ß√µes adicionais relevantes]

Use apenas os t√≥picos que tiverem informa√ß√£o no texto.
Seja objetivo e mantenha terminologia m√©dica.

TEXTO ORIGINAL:
${text}

Retorne apenas a lista formatada, sem coment√°rios.`,

  key_info: (text: string) => `Voc√™ √© um assistente m√©dico especializado em extrair informa√ß√µes cr√≠ticas.

TAREFA: Extraia APENAS as informa√ß√µes cr√≠ticas do texto:
1. Diagn√≥stico/Hip√≥tese diagn√≥stica
2. Sintomas principais (m√°ximo 3)
3. Conduta imediata
4. Alertas importantes (alergias, intera√ß√µes, etc)

Seja extremamente conciso (m√°ximo 200 palavras).
Mantenha apenas o essencial para tomada de decis√£o cl√≠nica.

TEXTO ORIGINAL:
${text}

Retorne apenas as informa√ß√µes-chave, sem coment√°rios.`,
};

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ id: string }> }
) {
  try {
    const { id } = await params;
    const supabase = await createClient();

    // Verificar autentica√ß√£o
    const {
      data: { user },
    } = await supabase.auth.getUser();

    if (!user) {
      return NextResponse.json(
        { error: "N√£o autenticado" },
        { status: 401 }
      );
    }

    // Verificar ownership da consulta
    const { data: consultation, error: consultationError } = await supabase
      .from("consultations")
      .select("id")
      .eq("id", id)
      .eq("doctor_id", user.id)
      .single();

    if (consultationError || !consultation) {
      return NextResponse.json(
        { error: "Consulta n√£o encontrada" },
        { status: 404 }
      );
    }

    // Parse request body
    const body: CondenseRequest = await request.json();
    const { field, mode, originalText } = body;

    // Valida√ß√µes
    if (!field || !mode || !originalText) {
      return NextResponse.json(
        { error: "Par√¢metros obrigat√≥rios: field, mode, originalText" },
        { status: 400 }
      );
    }

    if (!['summary', 'bullets', 'key_info'].includes(mode)) {
      return NextResponse.json(
        { error: "Modo inv√°lido. Use: summary, bullets, key_info" },
        { status: 400 }
      );
    }

    const originalLength = originalText.length;

    // Verificar se texto √© muito curto (n√£o precisa condensar)
    if (originalLength < 500) {
      return NextResponse.json({
        condensedText: originalText,
        originalLength,
        condensedLength: originalLength,
        compressionRatio: 0,
        skipped: true,
        reason: "Texto muito curto, n√£o precisa condensa√ß√£o",
      });
    }

    console.log(`üóúÔ∏è  Condensando campo ${field} no modo ${mode} (${originalLength} caracteres)`);

    // Chamar OpenAI para condensar
    const prompt = PROMPTS[mode](originalText);

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.3,
      max_tokens: 2000,
    });

    const condensedText = response.choices[0].message.content?.trim();

    if (!condensedText) {
      throw new Error("Resposta vazia da API");
    }

    const condensedLength = condensedText.length;
    const compressionRatio = Math.round(((originalLength - condensedLength) / originalLength) * 100);

    console.log(`‚úÖ Condensa√ß√£o conclu√≠da: ${originalLength} ‚Üí ${condensedLength} chars (${compressionRatio}% redu√ß√£o)`);

    return NextResponse.json({
      condensedText,
      originalLength,
      condensedLength,
      compressionRatio,
      skipped: false,
    });
  } catch (error: any) {
    console.error("‚ùå Erro ao condensar texto:", error);
    return NextResponse.json(
      { error: error.message || "Erro ao condensar texto" },
      { status: 500 }
    );
  }
}
