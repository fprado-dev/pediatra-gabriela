import { openai } from "./client";
import fs from "fs";

interface TranscribeOptions {
  audioPath: string;
  language?: string;
  prompt?: string;
}

/**
 * Transcreve um arquivo de √°udio usando Whisper API
 * @param options - Op√ß√µes de transcri√ß√£o
 * @returns Texto transcrito
 */
export async function transcribeAudio(options: TranscribeOptions): Promise<string> {
  const { audioPath, language = "pt", prompt } = options;

  try {
    console.log("üìù Iniciando transcri√ß√£o com Whisper...");
    
    // Ler o arquivo de √°udio
    const audioFile = fs.createReadStream(audioPath);

    // Prompt para contexto (ajuda o Whisper a entender termos m√©dicos)
    const contextPrompt = prompt || 
      "Consulta m√©dica pedi√°trica. Termos t√©cnicos: diagn√≥stico, sintomas, tratamento, prescri√ß√£o, anamnese, exame f√≠sico.";

    // Chamar API Whisper
    const response = await openai.audio.transcriptions.create({
      file: audioFile,
      model: "whisper-1",
      language,
      prompt: contextPrompt,
      response_format: "verbose_json", // Retorna timestamps e metadata
      temperature: 0.2, // Mais conservador para termos m√©dicos
    });

    console.log(`‚úÖ Transcri√ß√£o conclu√≠da (${response.duration}s de √°udio)`);
    
    return response.text;
  } catch (error: any) {
    console.error("‚ùå Erro na transcri√ß√£o:", error);
    throw new Error(`Erro ao transcrever √°udio: ${error.message}`);
  }
}
